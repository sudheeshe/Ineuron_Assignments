{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f65ba3ac",
   "metadata": {},
   "source": [
    "### 1. In the sense of machine learning, what is a model? What is the best way to train a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f006488",
   "metadata": {},
   "source": [
    "A machine learning model is a file that has been trained to recognize certain types of patterns. You train a model over a set of data, providing it an algorithm that it can use to reason over and learn from those data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901ed865",
   "metadata": {},
   "source": [
    "### 2. In the sense of machine learning, explain the \"No Free Lunch\" theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5825c6",
   "metadata": {},
   "source": [
    "The No Free Lunch Theorem is often thrown around in the field of optimization and machine learning, often with little understanding of what it means or implies. The theorem states that all optimization algorithms perform equally well when their performance is averaged across all possible problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb854c4",
   "metadata": {},
   "source": [
    "### 3. Describe the K-fold cross-validation mechanism in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22ef699",
   "metadata": {},
   "source": [
    "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\n",
    "\n",
    "The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation.\n",
    "\n",
    "Cross-validation is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data. That is, to use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model.\n",
    "\n",
    "The general procedure is as follows:\n",
    "\n",
    "- Shuffle the dataset randomly.\n",
    "- Split the dataset into k groups\n",
    "- For each unique group:\n",
    "\n",
    "    1) Take the group as a hold out or test data set\n",
    "    \n",
    "    2) Take the remaining groups as a training data set\n",
    "    \n",
    "    3) Fit a model on the training set and evaluate it on the test set\n",
    "    \n",
    "    4) Retain the evaluation score and discard the model\n",
    "    \n",
    "    \n",
    "- Summarize the skill of the model using the sample of model evaluation scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3649a9d",
   "metadata": {},
   "source": [
    "### 4. Describe the bootstrap sampling method. What is the aim of it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c338a1",
   "metadata": {},
   "source": [
    "Bootstrap Sampling is a method that involves drawing of sample data repeatedly with replacement from a data source to estimate a population parameter.\n",
    "\n",
    "Let’s break it down and understand the key terms:\n",
    "\n",
    "`Sampling:` With respect to statistics, sampling is the process of selecting a subset of items from a vast collection of items (population) to estimate a certain characteristic of the entire population\n",
    "\n",
    "`Sampling with replacement:` It means a data point in a drawn sample can reappear in future drawn samples as well\n",
    "\n",
    "`Parameter estimation:` It is a method of estimating parameters for the population using samples. A parameter is a measurable characteristic associated with a population. For example, the average height of residents in a city, the count of red blood cells, etc.\n",
    "\n",
    "\n",
    "When we have to estimate a parameter of a large population, we can take the help of Bootstrap Sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce4f6a",
   "metadata": {},
   "source": [
    "### 5. What is the significance of calculating the Kappa value for a classification model? Demonstrate how to measure the Kappa value of a classification model using a sample collection of results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de01d6e0",
   "metadata": {},
   "source": [
    "It basically tells you how much better your classifier is performing over the performance of a classifier that simply guesses at random according to the frequency of each class. Cohen's kappa is always less than or equal to 1. Values of 0 or less, indicate that the classifier is useless.\n",
    "\n",
    "Cohen’s kappa is more informative than overall accuracy when working with unbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eb5320",
   "metadata": {},
   "source": [
    "`Inter-rater reliability:` (to better understand reaters or Judges)\n",
    "\n",
    "Inter-rater reliability is the level of agreement between raters or judges. If everyone agrees, IRR is 1 (or 100%) and if everyone disagrees, IRR is 0 (0%). Several methods exist for calculating IRR, from the simple (e.g. percent agreement) to the more complex (e.g. Cohen's Kappa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7918ad00",
   "metadata": {},
   "source": [
    "In statistics, Cohen’s Kappa is used to measure the level of agreement between two raters or judges who each classify items into mutually exclusive categories.\n",
    "\n",
    "\n",
    "The formula for Cohen’s kappa is calculated as:\n",
    "\n",
    "`k = (po – pe) / (1 – pe)`\n",
    "\n",
    "where:\n",
    "\n",
    " - po: Relative observed agreement among raters\n",
    " - pe: Hypothetical probability of chance agreement\n",
    " \n",
    " \n",
    "Rather than just calculating the percentage of items that the raters agree on, Cohen’s Kappa attempts to account for the fact that the raters may happen to agree on some items purely by chance.\n",
    "\n",
    "The value for Cohen’s Kappa always ranges between 0 and 1where:\n",
    "\n",
    "  - 0 indicates no agreement between the two raters\n",
    "  - 1 indicates perfect agreement between the two raters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419869e1",
   "metadata": {},
   "source": [
    "`Example: Calculating Cohen’s Kappa in Python`\n",
    "    \n",
    "Suppose two art museum curators are asked to rate 15 paintings on whether they’re good enough to be shown in a new exhibit.\n",
    "\n",
    "The following code shows how to use the cohen_kappa_score() function from the sklearn library to calculate Cohen’s Kappa for the two raters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a66fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "#define array of ratings for both raters\n",
    "rater1 = [0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0]\n",
    "rater2 = [0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0]\n",
    "\n",
    "#calculate Cohen's Kappa\n",
    "cohen_kappa_score(rater1, rater2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3386001",
   "metadata": {},
   "source": [
    "Cohen’s Kappa turns out to be 0.33628.\n",
    "\n",
    "Based on the table from earlier, we would say that the two raters only had a “fair” level of agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6863639",
   "metadata": {},
   "source": [
    "### 6. Describe the model ensemble method. In machine learning, what part does it play?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3297153",
   "metadata": {},
   "source": [
    "Ensemble methods is a machine learning technique that combines several base models in order to produce one optimal predictive model\n",
    "\n",
    "The goal of any machine learning problem is to find a single model that will best predict our wanted outcome. Rather than making one model and hoping this model is the best/most accurate predictor we can make, ensemble methods take a myriad of models into account, and average those models to produce one final model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad837b2",
   "metadata": {},
   "source": [
    "### 7. What is a descriptive model's main purpose? Give examples of real-world problems that descriptive models were used to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b200e4",
   "metadata": {},
   "source": [
    "Descriptive modeling is a mathematical process that describes real-world events and the relationships between factors responsible for them. The process is used by consumer-driven organizations to help them target their marketing and advertising efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6211d800",
   "metadata": {},
   "source": [
    "### 8. Describe how to evaluate a linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47065bd",
   "metadata": {},
   "source": [
    "There are three error metrics that are commonly used for evaluating and reporting the performance of a regression model; they are:\n",
    "\n",
    "  - Mean Squared Error (MSE). : The MSE is calculated as the mean or average of the squared differences between predicted and expected target values in a dataset.\n",
    "\n",
    "  - Root Mean Squared Error (RMSE): RMSE, is an extension of the mean squared error. Importantly, the square root of the error is calculated, which means that the units of the RMSE are the same as the original units of the target value that is being predicted.\n",
    "  \n",
    "  - Mean Absolute Error (MAE): MAE score is calculated as the average of the absolute error values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e0e1b3",
   "metadata": {},
   "source": [
    "### 9. Distinguish :\n",
    "\n",
    "1. Descriptive vs. predictive models\n",
    "\n",
    "2. Underfitting vs. overfitting the model\n",
    "\n",
    "3. Bootstrapping vs. cross-validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043aef98",
   "metadata": {},
   "source": [
    "`Descriptive vs. predictive models:`\n",
    "\n",
    "    A descriptive model will exploit the past data that are stored in databases and provide you with the accurate report. In a Predictive model, it identifies patterns found in past and transactional data to find risks and future outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42037bdc",
   "metadata": {},
   "source": [
    "`Underfitting:`\n",
    "\n",
    "Underfitting the training data when the model performs poorly on the training data. This is because the model is unable to capture the relationship between the input examples (often called X) and the target values (often called Y)\n",
    "    \n",
    "The training data is not modelled and even no generalization of new data. Which gives poor performance in training and testinf data\n",
    "\n",
    "`Overfitting:`\n",
    "overfitting your training data when you see that the model performs well on the training data but does not perform well on the evaluation data. This is because the model is memorizing the data it has seen and is unable to generalize to unseen examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50d0514",
   "metadata": {},
   "source": [
    "`Bootstrapping vs. cross-validation`\n",
    "\n",
    "Cross validation splits the available dataset to create multiple datasets, and Bootstrapping method uses the original dataset to create multiple datasets after resampling with replacement. Bootstrapping it is not as strong as Cross validation when it is used for model validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac39c9d1",
   "metadata": {},
   "source": [
    "### 10. Make quick notes on:\n",
    "\n",
    "  1. LOOCV.\n",
    "\n",
    "  2. F-measurement\n",
    "\n",
    "  3. The width of the silhouette\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ffb251",
   "metadata": {},
   "source": [
    "`LOOCV(Leave One Out Cross-Validation)` \n",
    "\n",
    "LOOCV is a type of cross-validation approach in which each observation is considered as the validation set and the rest (N-1) observations are considered as the training set. In LOOCV, fitting of the model is done and predicting using one observation validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbb18ff",
   "metadata": {},
   "source": [
    "`F-Score:`\n",
    "    \n",
    "Fbeta-measure is a configurable single-score metric for evaluating a binary classification model based on the predictions made for the positive class. The Fbeta-measure is calculated using precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939cdab9",
   "metadata": {},
   "source": [
    "`Silhouette score:`\n",
    "\n",
    "Silhouette score is used to evaluate the quality of clusters created using clustering algorithms such as K-Means in terms of how well samples are clustered with other samples that are similar to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c41bb00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
