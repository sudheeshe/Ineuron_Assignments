{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dfb11af",
   "metadata": {},
   "source": [
    "### 1.\tWhat are the advantages of a CNN over a fully connected DNN for image classification?"
   ]
  },
  {
   "attachments": {
    "main-qimg-85600e4604a1354bdcfb29aed04b0a07-lq.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "id": "c7753462",
   "metadata": {},
   "source": [
    "In the case of deep neural networks each neuron in a given layer is fully connected to all the neurons in the previous layer. Because of these large number of connections the number of parameters to be learned increases. As the number of parameters increases the network becomes more complex. This more complexity of the network leads to overfitting.\n",
    "\n",
    "Especially, in the case of Image data being pixel values of the images as features, the number of input features would be of large dimension. And the most of the pixel portions of the images may not contribute in predicting the output as you can understand from the below picture. The highlighted pixel portions of the image doesn’t contribute in predicting whether it is dog or not.\n",
    "\n",
    "![main-qimg-85600e4604a1354bdcfb29aed04b0a07-lq.jpg](attachment:main-qimg-85600e4604a1354bdcfb29aed04b0a07-lq.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d8ef91",
   "metadata": {},
   "source": [
    "To overcome these challenges, the Convolution Neural Networks were discovered. In this, the input image data will be subjected to set of convolution operations such as filtration and max pooling. Then, the resultant data which will be of lesser dimension compared to the original image data will be subjected to Fully connected layers to predict output.\n",
    "\n",
    "By performing the convolution operations, the dimensionality of the data shrinks significantly large. Hence, the number of parameters to be learned decreases. Hence, the network complexity decreases which leads to less chances of overfitting!\n",
    "\n",
    "This is the reason why we use CNN’s while in the case of Image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92451b76",
   "metadata": {},
   "source": [
    "### 2.\tConsider a CNN composed of three convolutional layers, each with 3 × 3 kernels, a stride of 2, and \"same\" padding. The lowest layer outputs 100 feature maps, the middle one outputs 200, and the top one outputs 400. The input images are RGB images of 200 × 300 pixels.  What is the total number of parameters in the CNN? If we are using 32-bit floats, at least how much RAM will this network require when making a prediction for a single instance? What about when training on a mini-batch of 50 images?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f5d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, activations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d8b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(layers.Conv2D(400, kernel_size= 3, padding='same', strides=2, input_shape=(200, 300, 3)))\n",
    "model.add(layers.Conv2D(200, kernel_size= 3))\n",
    "model.add(layers.Conv2D(100, kernel_size= 3))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eaa133",
   "metadata": {},
   "source": [
    "### 3.\tIf your GPU runs out of memory while training a CNN, what are five things you could try to solve the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19046479",
   "metadata": {},
   "source": [
    "1. If you are working on image classification, then you can minimize the size of your input image.\n",
    "\n",
    "2. Use small size of filters (2x2 or 3x3) to the convolutional layer.\n",
    "\n",
    "3. In fully connected layer minimize the number of hidden layer and neuron numbers.\n",
    "\n",
    "4. Use overlapping pooling layer (max or average), sometimes it works so efficiently. For further reference please see the paper of AlexNet model.\n",
    "\n",
    "5. Data type changing (that means float32 to float16) can minimize the accuracy of CNN model but it is also helpful to save memory.\n",
    "\n",
    "6. Use mini batchs of images instead of taking all images at once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a06e522",
   "metadata": {},
   "source": [
    "### 4.\tWhy would you want to add a max pooling layer rather than a convolutional layer with the same stride?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb80a0",
   "metadata": {},
   "source": [
    "Max pooling is done to in part to help over-fitting by providing an abstracted form of the representation. As well, it reduces the computational cost by reducing the number of parameters to learn and provides basic translation invariance to the internal representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a930d5",
   "metadata": {},
   "source": [
    "### 5.\tWhen would you want to add a local response normalization layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99663324",
   "metadata": {},
   "source": [
    "The local normalization tends to uniformize the mean and variance of an image around a local neighborhood. This is especially useful for correct uneven illumination or shading artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bac447a",
   "metadata": {},
   "source": [
    "### 6.\tCan you name the main innovations in AlexNet, compared to LeNet-5? What about the main innovations in GoogLeNet, ResNet, SENet, and Xception?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fcf54a",
   "metadata": {},
   "source": [
    "The main innovation introduced by AlexNet compared to the LeNet-5 was its sheer size. AlexNet main elements are the same: a sequence of convolutional and pooling layers followed by a couple of fully-connected layers.\n",
    "\n",
    "`Resnet`: ResNet improves the efficiency of deep neural networks with more neural layers while minimizing the percentage of errors. In other words, the skip connections add the outputs from previous layers to the outputs of stacked layers, making it possible to train much deeper networks than previously possible.\n",
    "\n",
    "`GoogLeNet`: 1×1 convolution These convolutions used to decrease the number of parameters (weights and biases) of the architecture. By reducing the parameters we also increase the depth of the architecture. In GoogLeNet architecture, there is a method called global average pooling is used at the end of the network. This layer takes a feature map of 7×7 and averages it to 1×1. This also decreases the number of trainable parameters to 0 and improves the top-1 accuracy by 0.6%. The inception module is different from previous architectures such as AlexNet, ZF-Net. In this architecture, there is a fixed convolution size for each layer.\n",
    "In the Inception module 1×1, 3×3, 5×5 convolution and 3×3 max pooling performed in a parallel way at the input and the output of these are stacked together to generated final output. The idea behind that convolution filters of different sizes will handle objects at multiple scale better.\n",
    "\n",
    "\n",
    "`Xception`: The modified depthwise separable convolution is the pointwise convolution followed by a depthwise convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31caede",
   "metadata": {},
   "source": [
    "### 7.\tWhat is a fully convolutional network? How can you convert a dense layer into a convolutional layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2ad7cc",
   "metadata": {},
   "source": [
    "Fully Connected Layer is simply, feed forward neural networks. Fully Connected Layers form the last few layers in the network. The input to the fully connected layer is the output from the final Pooling or Convolutional Layer, which is flattened and then fed into the fully connected layer.\n",
    "\n",
    "A fully convolution network can be built by simply replacing the FC layers with there equivalent Conv layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c59968",
   "metadata": {},
   "source": [
    "### 8.\tWhat is the main technical difficulty of semantic segmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340add99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40ddb4ee",
   "metadata": {},
   "source": [
    "### 9.\tBuild your own CNN from scratch and try to achieve the highest possible accuracy on MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0291b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten, Dropout\n",
    "\n",
    "\n",
    "img_rows, img_cols=28, 28\n",
    " \n",
    "if k.image_data_format() == 'channels_first':\n",
    "   x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "   x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "   inpx = (1, img_rows, img_cols)\n",
    " \n",
    "else:\n",
    "   x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "   x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "   inpx = (img_rows, img_cols, 1)\n",
    " \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "inpx = Input(shape=inpx)\n",
    "layer1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(inpx)\n",
    "layer2 = Conv2D(64, (3, 3), activation='relu')(layer1)\n",
    "layer3 = MaxPooling2D(pool_size=(3, 3))(layer2)\n",
    "layer4 = Dropout(0.5)(layer3)\n",
    "layer5 = Flatten()(layer4)\n",
    "layer6 = Dense(250, activation='sigmoid')(layer5)\n",
    "layer7 = Dense(10, activation='softmax')(layer6)\n",
    "\n",
    "\n",
    "model = Model([inpx], layer7)\n",
    "model.compile(optimizer=keras.optimizers.Adadelta(), \n",
    "              loss=keras.losses.categorical_crossentropy, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=12, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7176c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00a91d9",
   "metadata": {},
   "source": [
    "### 10.\tUse transfer learning for large image classification, going through these steps:\n",
    "\n",
    "- a.\tCreate a training set containing at least 100 images per class. For example, you could classify your own pictures based on the location (beach, mountain, city, etc.), or alternatively you can use an existing dataset (e.g., from TensorFlow Datasets).\n",
    "\n",
    "- b.\tSplit it into a training set, a validation set, and a test set.\n",
    "\n",
    "- c.\tBuild the input pipeline, including the appropriate preprocessing operations, and optionally add data augmentation.\n",
    "\n",
    "- d.\tFine-tune a pretrained model on this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (160, 160)\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
    "                                                            shuffle=True,\n",
    "                                                            batch_size=BATCH_SIZE,\n",
    "                                                            image_size=IMG_SIZE)\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\n",
    "                                                                 shuffle=True,\n",
    "                                                                 batch_size=BATCH_SIZE,\n",
    "                                                                 image_size=IMG_SIZE)\n",
    "\n",
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(val_batches // 5)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 5)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
    "\n",
    "  # Create the base model from the pre-trained model MobileNet V2\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "\n",
    "prediction_layer = tf.keras.layers.Dense(1)\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "initial_epochs = 10\n",
    "\n",
    "loss0, accuracy0 = model.evaluate(validation_dataset)\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7df6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a308544",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a2f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "\n",
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "fine_tune_epochs = 10\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69134a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylim([0.8, 1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceee900",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print('Test accuracy :', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
