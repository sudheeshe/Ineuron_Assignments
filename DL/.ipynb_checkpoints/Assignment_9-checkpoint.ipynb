{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a1084be",
   "metadata": {},
   "source": [
    "### 1.\tWhat are the main tasks that autoencoders are used for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6638d8b",
   "metadata": {},
   "source": [
    "Autoencoders are applied to many problems, including facial recognition, feature detection, anomaly detection and acquiring the meaning of words. Autoencoders are also generative models which can randomly generate new data that is similar to the input data (training data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12553a4b",
   "metadata": {},
   "source": [
    "### 2.\tSuppose you want to train a classifier, and you have plenty of unlabeled training data but only a few thousand labeled instances. How can autoencoders help? How would you proceed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce9971",
   "metadata": {},
   "source": [
    "To train an autoencoder we don’t need to do anything fancy, just throw the raw input data at it. Autoencoders are considered an unsupervised learning technique since they don’t need explicit labels to train on. But to be more precise they are self-supervised because they generate their own labels from the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7693fc62",
   "metadata": {},
   "source": [
    "### 3.\tIf an autoencoder perfectly reconstructs the inputs, is it necessarily a good autoencoder? How can you evaluate the performance of an autoencoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cb8e6c",
   "metadata": {},
   "source": [
    "If you consider conventional autoencoder function, yes, it is a good autoencoder. In practice, efficiency of autoencoder depends on how well it reconstructs and also on how robust it is to noise in different scenes.\n",
    "\n",
    "Common practice is to add noise sampled from input distribution to the input space to make sure autoencoder, vanilla or VAE, learns to reconstruct the input more robustly regardless of scenic distortions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7111f415",
   "metadata": {},
   "source": [
    "### 4.\tWhat are undercomplete and overcomplete autoencoders? What is the main risk of an excessively undercomplete autoencoder? What about the main risk of an overcomplete autoencoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effabab4",
   "metadata": {},
   "source": [
    "`Undercomplete Autoencoder`\n",
    "\n",
    "- This is when our encoding output's dimension is smaller than our input's dimension.\n",
    "- Essentially we reduced the dimension of our data (dimensionality reduction) with an undercomplete AE\n",
    "\n",
    "`Overcomplete Autoencoder`\n",
    "\n",
    "- This is when our encoding output's dimension is larger than our input's dimension\n",
    "- Essentially we increased the dimension of our data with an overcomplete AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3b97b",
   "metadata": {},
   "source": [
    "If we excessively undercomplete autoencoder the volume of the space increases so fast that the available data become sparse.\n",
    "\n",
    "The main risk of an overcomplete autoencoder It may lead to some amount of data loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675dc077",
   "metadata": {},
   "source": [
    "### 5.\tHow do you tie weights in a stacked autoencoder? What is the point of doing so?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d0e32d",
   "metadata": {},
   "source": [
    "An autoencoder with tied weights has decoder weights that are the transpose of the encoder weights; this is a form of parameter sharing, which reduces the number of parameters of the model.\n",
    "\n",
    "Autoencoders with tied weights have some important advantages :\n",
    "\n",
    "It's easier to learn.\n",
    "In linear case it's equvialent to PCA - this may lead to more geometrically adequate coding.\n",
    "Tied weights are sort of regularisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb83ac2",
   "metadata": {},
   "source": [
    "### 6.\tWhat is a generative model? Can you name a type of generative autoencoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b565c61",
   "metadata": {},
   "source": [
    "Generative models are considered as a class of statistical models that can generate new data instances. These models are used in unsupervised machine learning as a means to perform tasks such as\n",
    "\n",
    "- Probability and Likelihood estimation,\n",
    "- Modeling data points,\n",
    "- To describe the phenomenon in data,\n",
    "- To distinguish between classes based on these probabilities.\n",
    "\n",
    "Example: GAN'S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d24fefb",
   "metadata": {},
   "source": [
    "### 7.\tWhat is a GAN? Can you name a few tasks where GANs can shine?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aba6c9b",
   "metadata": {},
   "source": [
    "Generative Adversarial Networks (GANs) are a powerful class of neural networks that are used for unsupervised learning. GANs are basically made up of a system of two competing neural network models which compete with each other and are able to analyze, capture and copy the variations within a dataset.\n",
    "\n",
    "1) Image-to-Image Translation\n",
    "\n",
    "2) Text-to-Image Synthesis\n",
    "\n",
    "3) Super-resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6abe0e",
   "metadata": {},
   "source": [
    "### 8.\tWhat are the main difficulties when training GANs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f11081",
   "metadata": {},
   "source": [
    "Major challenges in training of GANs, i.e., mode collapse, non-convergence and instability, due to inappropriate design of network architecture, use of objective function and selection of optimization algorithm.  The reason they are difficult to train is that both the generator model and the discriminator model are trained simultaneously in a game. This means that improvements to one model come at the expense of the other model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e012fbae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
